{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/foroughkarandish/Convolutional-Neural-Network-Architecture/blob/master/Convolutional_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4OD9aCMb8FSA"
   },
   "source": [
    "This project is not completed yet and I am thinking about the best way to explain and implement it. Stay tuned for updates!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qaaCS_M17CYC"
   },
   "source": [
    "In this project I will explain CNN and use them to build an image classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "saU-9akIbKCm"
   },
   "source": [
    "**Table of Contents**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mJGQhqP1ZHwY"
   },
   "source": [
    "1. [Introduction](#1)<br>\n",
    "2. [Load Packages](#2)<br>\n",
    "    A. [Import](#21)<br>\n",
    "    B. [Setup](#22)<br>\n",
    "    C. [Version](#23)<br>\n",
    "3. [CNN Architecture](#43)<br>\n",
    "  A. [Convolutional Layers](#31)<br>\n",
    "  B. [Spatial arrangement](#32)<br>\n",
    "  C. [Pooling layers](#33) <br>\n",
    "  F. [Fully connected layer](#34) <br>\n",
    "  G. [A simple convolution network example](#37) <br>\n",
    "  H. [Pooling layers](#38) <br>\n",
    "  I. [Convolutional neural network example](#39) <br> \n",
    "  J. [Why convolutions?](#399) <br>\n",
    "5. [Model developement](#5)<br>\n",
    "    A. [Keras](#51)<br>   \n",
    "6. [References](#6)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AbVCMQD_gtIJ"
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZmKZflicgmUi"
   },
   "source": [
    "In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery. They are also known as shift invariant or space invariant artificial neural networks (SIANN), based on their shared-weights architecture and translation invariance characteristics. They have applications in image and video recognition, recommender systems, image classification, medical image analysis, natural language processing, and financial time series.<br>\n",
    "\n",
    "\n",
    "Convolutional networks were inspired by biological processes in that the connectivity pattern between neurons resembles the organization of the animal visual cortex. Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field. The receptive fields of different neurons partially overlap such that they cover the entire visual field.<br>\n",
    "\n",
    "\n",
    "CNNs use relatively little pre-processing compared to other image classification algorithms. This means that the network learns the filters that in traditional algorithms were hand-engineered. This independence from prior knowledge and human effort in feature design is a major advantage [1].<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yjZ-WcBQn5Kt"
   },
   "source": [
    "<a id=\"2\"></a>\n",
    "### A. Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "khxqifsXnhIX",
    "outputId": "b2d61f8f-ac9d-4a7e-c9a4-53ac0aa171fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, preprocessing, metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import get_dummies\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BTNrb9j-p9Wj"
   },
   "source": [
    "<a id=\"22\"></a>\n",
    "### B. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dc2IJLtmqSJX"
   },
   "source": [
    "I'm setting up essential visualisation here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_lxMQm-6qUC1"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%precision 4\n",
    "plt.style.use('ggplot')\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option(\"display.precision\", 15)\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Graphics in retina format are more sharp and legible\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXoGuI7-qY0l"
   },
   "source": [
    "<a id=\"33\"></a>\n",
    "### C. Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EtFVrpxwql-d"
   },
   "source": [
    "Checking the versions of my main libraries that I'm going to use in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "87NqTiARqk3E",
    "outputId": "f5cfc3ed-1eb8-4051-af19-3a4ad5657ab9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib: 3.2.2\n",
      "sklearn: 0.22.2.post1\n",
      "seaborn: 0.10.1\n",
      "pandas: 1.0.5\n",
      "numpy: 1.18.5\n"
     ]
    }
   ],
   "source": [
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "print('seaborn: {}'.format(sns.__version__))\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('numpy: {}'.format(np.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RfKenL7psHCI"
   },
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3. CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h0u-GutZsOrA"
   },
   "source": [
    "A convolutional neural network consists of an input and an output layer, as well as multiple hidden layers. The hidden layers of a CNN typically consist of a series of convolutional layers that convolve with a multiplication or other dot product. The activation function is commonly a RELU layer, and is subsequently followed by additional convolutions such as pooling layers, fully connected layers and normalization layers, referred to as hidden layers because their inputs and outputs are masked by the activation function and final convolution.\n",
    "\n",
    "Though the layers are colloquially referred to as convolutions, this is only by convention. Mathematically, it is technically a sliding dot product or cross-correlation. This has significance for the indices in the matrix, in that it affects how weight is determined at a specific index point[1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PERSKHqkz2__"
   },
   "source": [
    " <a id=\"31\"></a>\n",
    "### A. Convolutional Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4GzAmwl-0BV-"
   },
   "source": [
    "The convolutional layer is the core building block of a CNN. The layer's parameters consist of a set of learnable filters (or kernels), which have a small receptive field, but extend through the full depth of the input volume. During the forward pass, each filter is convolved across the width and height of the input volume, computing the dot product between the entries of the filter and the input and producing a 2-dimensional activation map of that filter. As a result, the network learns filters that activate when it detects some specific type of feature at some spatial position in the input.<br>\n",
    "\n",
    "Stacking the activation maps for all filters along the depth dimension forms the full output volume of the convolution layer. Every entry in the output volume can thus also be interpreted as an output of a neuron that looks at a small region in the input and shares parameters with neurons in the same activation map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://lh3.googleusercontent.com/proxy/vwhvX8emIF533r5aLt90gF9nNyYbGwx0LAj-heVwcdRb3q3XugTymFohgtRqKLClE4MFd1pC-yQt27Wor5jhOJQi0I-qdRaukls9pI-_yq9SdoKg85JlD0IEZXiEUytrbcgLOqzByfzggzQ\" width=\"800\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"32\"></a>\n",
    "### B. Spatial arrangement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Depth:**<br>\n",
    " The depth of the output volume controls the number of neurons in a layer that connect to the same region of the input volume. These neurons learn to activate for different features in the input. For example, if the first convolutional layer takes the raw image as input, then different neurons along the depth dimension may activate in the presence of various oriented edges, or blobs of color.\n",
    "- **Stride:**<br>\n",
    " Stride controls how depth columns around the spatial dimensions (width and height) are allocated. When the stride is 1 then we move the filters one pixel at a time. This leads to heavily overlapping receptive fields between the columns, and also to large output volumes. When the stride is 2 then the filters jump 2 pixels at a time as they slide around. Similarly, for any integer $S > 0 $, a stride of S causes the filter to be translated by S units at a time per output. In practice, stride lengths of $S \\geq 3$ are rare. The receptive fields overlap less and the resulting output volume has smaller spatial dimensions when stride length is increased.\n",
    "- **Padding:**<br>\n",
    " Sometimes it is convenient to pad the input with zeros on the border of the input volume. The size of this padding is a third hyperparameter. Padding provides control of the output volume spatial size. In particular, sometimes it is desirable to exactly preserve the spatial size of the input volume.\n",
    "The spatial size of the output volume can be computed as a function of the input volume size $W$, the kernel field size of the convolutional layer neurons $K$, the stride with which they are applied $S$, and the amount of zero padding $P$ used on the border. The formula for calculating how many neurons \"fit\" in a given volume is given by\n",
    "\n",
    "$$\\frac{W - K + 2P}{S} +1$$\n",
    "\n",
    "If this number is not an integer, then the strides are incorrect and the neurons cannot be tiled to fit across the input volume in a symmetric way. In general, setting zero padding to be $$ P=\\frac{K-1}{2}$$ when the stride is $S=1$ ensures that the input volume and output volume will have the same size spatially. However, it's not always completely necessary to use all of the neurons of the previous layer. For example, a neural network designer may decide to use just a portion of padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/325/1*b77nZmPH15dE8g49BLW20A.png\" width=\"300\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"33\"></a>\n",
    "### C. Pooling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important concept of CNNs is pooling, which is a form of non-linear down-sampling. There are several non-linear functions to implement pooling among which max pooling is the most common. It partitions the input image into a set of non-overlapping rectangles and, for each such sub-region, outputs the maximum.<br>\n",
    "\n",
    "Intuitively, the exact location of a feature is less important than its rough location relative to other features. This is the idea behind the use of pooling in convolutional neural networks. The pooling layer serves to progressively reduce the spatial size of the representation, to reduce the number of parameters, memory footprint and amount of computation in the network, and hence to also control overfitting. It is common to periodically insert a pooling layer between successive convolutional layers (each one typically followed by a ReLU layer) in a CNN architecture.The pooling operation can be used as another form of translation invariance.<br>\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e9/Max_pooling.png\" width=\"500\" height=\"500\">\n",
    "\n",
    "\n",
    "In addition to max pooling, pooling units can use other functions, such as **average pooling** or **â„“2-norm pooling**.<br> Average pooling was often used historically but has recently fallen out of favor compared to max pooling, which performs better in practice.\n",
    "\n",
    "Due to the aggressive reduction in the size of the representation, there is a recent trend towards using smaller filters or discarding pooling layers altogether.\n",
    "\n",
    "**RoI pooling** to size 2x2. In this example region proposal (an input parameter) has size 7x5.\n",
    "\"Region of Interest\" pooling (also known as RoI pooling) is a variant of max pooling, in which output size is fixed and input rectangle is a parameter.\n",
    "\n",
    "Pooling is an important component of convolutional neural networks for object detection based on Fast R-CNN architecture.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/d/dc/RoI_pooling_animated.gif\" width=\"350\" height=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"34\"></a>\n",
    "### D. Fully connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, after several convolutional and max pooling layers, the high-level reasoning in the neural network is done via fully connected layers. Neurons in a fully connected layer have connections to all activations in the previous layer, as seen in regular (non-convolutional) artificial neural networks. Their activations can thus be computed as an affine transformation, with matrix multiplication followed by a bias offset (vector addition of a learned or fixed bias term)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCHSxqmTm3l0"
   },
   "source": [
    "<a id=\"6\"></a>\n",
    "## 6. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eUSLAlYcm7Hm"
   },
   "source": [
    "[1]. [wiki](https://en.wikipedia.org/wiki/Convolutional_neural_network)<br>\n",
    "[2]. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNa+qf/AWib3eDXFZHDStBK",
   "include_colab_link": true,
   "name": "Convolutional Neural Network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
